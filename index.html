<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Nikita Starodubcev</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Nikita Starodubcev">
    <link rel="icon" type="images/png" href="images/photo.png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:890px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color:#f5f5f5;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;padding:5.5%">
                  Nikita Starodubcev
                </p>
                <p align="justify">
                  I am a first-year PhD student at <a href="https://research.yandex.com/">Yandex Research</a>, <a href="https://www.hse.ru/en/">HSE University</a>,
                  under the supervision of <a href="https://scholar.google.com/citations?hl=ru&user=2Kv3JP0AAAAJ&view_op=list_works">Artem Babenko</a>.
                  My research focuses on distilled diffusion models and their application in image editing and generation.
                  Before that, I worked at <a href="https://en.itmo.ru/">ITMO</a> developing open-source software frameworks.
                  My main goal is to enhance generative models in order to ensure their greater efficacy in real-world applications.
                  I am always open to new collaborations and highly motivated to work on cutting-edge research projects.
                </p>
                <p style="text-align:center">
                  <a href="mailto:nstarodubtsev@hse.ru">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.ru/citations?user=o6pRm_gAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="CV/cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://github.com/quickjkee">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/photo.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/photo.png" class="hoverZoomLink"></a>
                <i style="padding:22.65%">Chaising the unattainable...</i>
              </td>
            </tr>
          </tbody></table>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:20px;width:100%;vertical-align:middle;text-align: center;">
      <h1>Research projects</h1>
    </td>
  </tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/invertible-cd.png" alt="clean-usnob" width="360" height="123.71">
    </td>
    <td width="75%" valign="middle">
      <i>Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps</i><p class="project-conf-label in-proceedings">arXiv</p><br> <br>
      <strong>Nikita Starodubcev</strong>,
      <a href="https://scholar.google.com/citations?user=BWLDIa8AAAAJ&hl">Mikhail Khoroshikh</a>,
      <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ&hl">Artem Babenko</a>,
      <a href="https://scholar.google.com/citations?hl=ru&user=NiPmk8oAAAAJ">Dmitry Baranchuk</a>
      <br><a href="https://yandex-research.github.io/invertible-cd/"><img src='https://img.shields.io/badge/Project-Page-Green' /></a>
      <i style="font-size: 30px">/</i>
      <a href="https://huggingface.co/spaces/dbaranchuk/iCD-image-editing">
        <img src='https://img.shields.io/badge/%F0%9F%A4%97%20Demo-Editing-orange'/>
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://github.com/yandex-research/invertible-cd">
        <img style="height=20.7;padding-top: 8px;" src="https://img.shields.io/badge/Github-Code-white">
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://arxiv.org/abs/2406.14539"><img src="https://img.shields.io/badge/arXiv-Paper-b31b1b.svg"></a>
      <br>
      <p>We consider Consistency Distillation from the perspective of inversion, unlocking its potential for applications such as text-guided image editing.</p>
    </td>
  </tr>



  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <br><br>
      <img src="images/adaptive.png" alt="clean-usnob" width="360" height="182.74">
    </td>
    <td width="75%" valign="middle">
      <br><br>
      <i>Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models</i>
      <p class="project-conf-label in-proceedings">CVPR 2024</p><br>
      <br>
      <strong>Nikita Starodubcev</strong>,
      Artem Fedorov,
      <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ&hl">Artem Babenko</a>,
      <a href="https://scholar.google.com/citations?hl=ru&user=NiPmk8oAAAAJ">Dmitry Baranchuk</a>
      <a href="https://github.com/yandex-research/adaptive-diffusion">
        <img style="height=20.7;padding-top: 8px;" src="https://img.shields.io/badge/Github-Code-white">
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://arxiv.org/abs/2312.10835">
        <img style="height=20.7" src="https://img.shields.io/badge/arXiv-Paper-b31b1b.svg">
      </a>
      <br>
      <p>We show that a distilled model can sometimes outperform its teacher, despite being trained to approximate it. Based on the insights, we propose an adaptive teacher-student collaboration approach for image generation and text-guided editing.</p>
    </td>
  </tr>

  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/eff-diff.png" alt="clean-usnob" width="360" height="292.68">
    </td>
    <td width="75%" valign="middle">
      <br><br>
      <i>Towards Real-time Text-driven Image Manipulation with Unconditional Diffusion Models</i>
      <p class="project-conf-label in-proceedings">arXiv</p><br>
      <br>
      <strong>Nikita Starodubcev</strong>,
      <a href="https://scholar.google.com/citations?hl=ru&user=NiPmk8oAAAAJ">Dmitry Baranchuk</a>
      <a href="https://scholar.google.com/citations?user=GS5HTlkAAAAJ&hl=en">Valentin Khrulkov</a>,
      <a href="https://scholar.google.ru/citations?user=2Kv3JP0AAAAJ&hl">Artem Babenko</a>,
      <a href="https://github.com/quickjkee/eff-diff-edit">
        <img style="height=20.7;padding-top: 8px;" src="https://img.shields.io/badge/Github-Code-white">
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://arxiv.org/abs/2304.04344">
        <img style="height=20.7" src="https://img.shields.io/badge/arXiv-Paper-b31b1b.svg">
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://colab.research.google.com/drive/1rtu01eOB2gwr_j0gSyzXgkbMUKL_mNIx?usp=sharing">
        <img style="height=20.7" src="https://colab.research.google.com/assets/colab-badge.svg">
      </a>
      <br>
      <p>We propose an efficient fine-tuning based approach for domain adaptation of unconditional diffusion models, which works in about 4 seconds and requires 10 GiB of memory. Our method can compete with heavyweight text-conditional diffusion models
        on human faces editing.</p>
    </td>
  </tr>

  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/gefest.png" alt="clean-usnob" width="360" height="142.85">
    </td>
    <td width="75%" valign="middle">
      <br><br>
      <i>Generative design of physical objects using modular framework</i>
      <p class="project-conf-label in-proceedings">EAAI 2023</p><br>
      <br>
      <strong>Nikita Starodubcev</strong>,
      <a href="https://github.com/nicl-nno">Nikolay N.</a>,
      Elizaveta A.,
      Konstantin G.,
      <a href="https://scholar.google.ru/citations?user=0Iv7cL0AAAAJ&hl=ru&oi=sra">Denis S.</a>,
      <a href="https://scholar.google.ru/citations?user=bjiILqcAAAAJ&hl=ru&oi=sra">Anna K.</a>,
      <a href="https://github.com/aimclub/GEFEST">
        <img style="height=20.7;padding-top: 8px;" src="https://img.shields.io/badge/Github-Code-white">
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197622007059">
        <img style="height=20.7" src="https://img.shields.io/badge/Elsevier-Paper-orange">
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://arxiv.org/pdf/2207.14621">
        <img style="height=20.7" src="https://img.shields.io/badge/arXiv-Paper-b31b1b.svg">
      </a>
      <br>
      <p>This work proposes an open-source framework aimed at generating novel engineering objects with unique properties.
        For example, we investigate the optimization of hydrodynamic red blood cell traps needed for disease diagnosis.
       </p>
    </td>
  </tr>





  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color"><tbody>
  <tr>
    <td style="padding:20px;width:100%;vertical-align:middle;text-align: center;">
      <h1>Toy projects</h1>
    </td>
  </tr>
</tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color"><tbody>
  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/ip2p-distill.png" alt="clean-usnob" width="360" height="160">
    </td>
    <td width="75%" valign="middle">
      <br><br>
      <i>Fast InstructPix2Pix using Distilled Text-conditional Diffusion Models</i>
      <br> <br>
      <a href="https://github.com/quickjkee/instruct-pix2pix-distill">
        <img style="height=20.7;padding-top: 8px;" src="https://img.shields.io/badge/Github-Code-white">
      </a>
      <i style="font-size: 30px">/</i>
      <a href="https://huggingface.co/spaces/dbaranchuk/instruct-p2p-distill">
        <img src='https://img.shields.io/badge/%F0%9F%A4%97%20Demo-Editing-orange'/>
      </a>
      <br>
      <p>
        In this project, the acceleration of the <a href="https://github.com/timothybrooks/instruct-pix2pix/tree/main">IntructPix2Pix</a> model is achieved
        using the distilled diffusion models: <a href="https://arxiv.org/abs/2310.04378">Latent Consistency Models</a>
        and <a href="https://arxiv.org/abs/2311.17042">Adversarial Diffusion Distillation</a>. The IntructPix2Pix adapts through simple weight geometry.
        This allows us to speed up editing by about 4 times without noticeable quality degradation.
       </p>
    </td>
  </tr>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color"><tbody>
  <tr>
    <td style="padding:20px;width:25%;vertical-align:middle">
      <img src="images/toy.png" alt="clean-usnob" width="360" height="160">
    </td>
    <td width="75%" valign="middle">
      <br><br>
      <i>Journey through generative modeling</i>
      <br> <br>
      <a href="https://github.com/quickjkee/Journey-through-generative-modeling">
        <img style="height=20.7;padding-top: 8px;" src="https://img.shields.io/badge/Github-Code-white">
      </a>
      <br>
      <p>
        In this work, I dive into the theory of recent works on generative models in order to gain a complete understanding.
        The goal is to identify further research directions and answer interesting questions that have not been covered in the papers.
       </p>
    </td>
  </tr>

</html>